{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288722d9-c467-4ba7-9f3e-d47428951b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d5e5e-fe15-4e99-b39c-efc4175083a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USUARIO = \"\"\n",
    "\n",
    "if not USUARIO:\n",
    "    raise RuntimeError(\"Por favor escriba su usuario Uniandes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb90b4-f19b-430a-b064-5ba4c68c5b2d",
   "metadata": {},
   "source": [
    "# Creamos la sesión de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c784bf-dd33-45a6-88ad-ff82e51f7db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder \n",
    "        .appName(\"streaming_data\") \n",
    "        .master(\"local[1]\")\n",
    "        .config(\n",
    "            \"spark.sql.extensions\",\n",
    "            \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    "        )\n",
    "        .config(\n",
    "            \"spark.sql.catalog.spark_catalog\",\n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "        )\n",
    "        .config(\n",
    "            \"fs.azure.account.key.streamingclass.dfs.core.windows.net\",\n",
    "            os.environ.get(\"AZURE_KEY\")\n",
    "        )\n",
    "        .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25426d-cb20-4672-9fc2-84ffa06df8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58daaf-aa10-46f8-b9c7-086dd0576de6",
   "metadata": {},
   "source": [
    "# Cargar datos de referencia de los sensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce28cd-150f-4f99-be58-66c64f3ac411",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_referencia = spark.read.format(\"json\").load(f\"abfss://data@streamingclass.dfs.core.windows.net/datos/sensores.json\")\n",
    "\n",
    "datos_referencia.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68168ef-58ee-4c10-ab88-e645f10d100f",
   "metadata": {},
   "source": [
    "## Conectarse a un tema de Kafka como fuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd1013-b3bd-4266-b3b4-f019b2f1e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = os.environ[\"KAFKA_CONNECTION_STRING\"]\n",
    "JAAS_CONFIG = f'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{CONNECTION_STRING}\";'\n",
    "\n",
    "df_kafka = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"https://clase-streaming.servicebus.windows.net:9093\")\n",
    "    .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .option(\"kafka.sasl.jaas.config\", JAAS_CONFIG)\n",
    "    .option(\"subscribe\", \"sensores\")\n",
    "    .option(\"startingOffsets\",\"latest\") # podría ser \"earliest\", \"latest\" o \"\"\"{\"tema\":{\"0\":23,\"1\":-1}} \"\"\"\n",
    "    .load()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239b3f3-082c-4511-b373-53d225d6bd47",
   "metadata": {},
   "source": [
    "# Consultar los datos en consola para depuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a2097-c3ed-4254-bbd5-58f4996d7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    df_kafka.writeStream\n",
    "    .format(\"console\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", f\"abfss://data@streamingclass.dfs.core.windows.net/{USUARIO}/checkpoint\")\n",
    "    .start()\n",
    ") \n",
    "\n",
    "# Esperamos 10 segundos\n",
    "sleep(30)\n",
    "\n",
    "# Finalizamos el proceso\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2ff90-fba4-4f6a-b7b0-404f5751e264",
   "metadata": {},
   "source": [
    "# Procesamiento de cada batch con foreachBatch\n",
    "\n",
    "En este ejemplo solo imprimimos en pantalla, pero puede incluirse una lógica propia, por ejemplo para hacer un upsert en una tabla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0df186-e0ba-4fce-afb3-648688f59e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Parseamos key y value que son campos binarios\n",
    "\n",
    "# Definimos el esquema:\n",
    "json_schema = StructType([\n",
    "    StructField(\"temperatura\", StringType(), True),\n",
    "    StructField(\"funcionamiento\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_parseado = (\n",
    "    df_kafka\n",
    "    .select(\n",
    "        f.col(\"key\").cast(\"string\"),\n",
    "        f.from_json(f.col(\"value\").cast(\"string\"), json_schema).alias(\"data\"),\n",
    "        \"timestamp\"\n",
    "    )\n",
    "    .select(\n",
    "        \"key\",\n",
    "        \"data.temperatura\",\n",
    "        \"data.funcionamiento\",\n",
    "        \"timestamp\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df_parseado.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19adc21-dfca-4682-825b-502a2ffbaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir(x, epoch_id):\n",
    "    \"\"\" \n",
    "    Función de ejemplo que simplemente imprime el lote\n",
    "    \"\"\"\n",
    "    print(f\"epoch_id: {epoch_id}\")\n",
    "    x.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ef174-8943-4b12-bdb8-23126326e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    df_parseado\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .foreachBatch(imprimir)\n",
    "    .start()\n",
    ") \n",
    "\n",
    "# Esperamos 10 segundos\n",
    "sleep(30)\n",
    "\n",
    "# Finalizamos el proceso\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3cc29-ba09-4f01-b164-d65a176e4cd3",
   "metadata": {},
   "source": [
    "# Cálculo de la temperatura promedio de cada sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40680760-39c3-4809-9e4b-6927c60440c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos y calculamos el promedio de deperatura\n",
    "temperatura_por_sensor_ventana = (\n",
    "    df_parseado\n",
    "    .withWatermark(\"timestamp\", \"15 seconds\")\n",
    "    .groupby(\"key\", f.window(\"timestamp\", \"10 seconds\"))\n",
    "    .agg(f.mean(\"temperatura\"))\n",
    ")\n",
    "\n",
    "query = (\n",
    "    temperatura_por_sensor_ventana\n",
    "    .writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .option(\"checkpointLocation\", f\"abfss://data@streamingclass.dfs.core.windows.net/{USUARIO}/checkpoint4\")\n",
    "    .format(\"console\")\n",
    "    .start()\n",
    ") \n",
    "\n",
    "# Esperamos 10 segundos\n",
    "sleep(30)\n",
    "\n",
    "# Finalizamos el proceso\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132ca52-4fec-4c4c-9a4f-3cee7dbef487",
   "metadata": {},
   "source": [
    "# Retos\n",
    "\n",
    "* **Escribir en un almacenamiento cada vez que un sensor tenga una temperatura mayor a 35 grados.**\n",
    "\n",
    "abfss://data@streamingclass.dfs.core.windows.net/{USUARIO}/mayor_a_35\n",
    "\n",
    "* **Publicar en Kafka cada vez que un sensor supere su variación máxima de temperatura de acuerdo a la tabla de referencia. Debe escribirse cada 10 segundos, pero esperar valores retrasados hasta 10 segundos más.**\n",
    "\n",
    "\n",
    "* **Crear un reporte que muestre cuántas veces cada sensor ha reportado un estado \"Incorrecto\" en cada minuto.**\n",
    "\n",
    "En consola\n",
    "\n",
    "* **Calcular la temperatura promedio de cada sensor durante los últimos 30 segundos, actualizando el cálculo cada 10 segundos**\n",
    "\n",
    "En consola"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
